{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f95e42",
   "metadata": {},
   "source": [
    "### Balancing Cartpole via a Random Sampling Agent using OpenAI Gym ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656a9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the necessary libraries ##\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3955c5",
   "metadata": {},
   "source": [
    "In this project we are going to implement a random agent which acts to balancing a Cartpole. Ofcourse, it would do badly, but this would give us an idea of working with Openai Gym platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c541e2",
   "metadata": {},
   "source": [
    "For any RL project we need to create two things:\n",
    "1. Environment\n",
    "2. Agent\n",
    "\n",
    "Creating a cartpole environment with OpenAI Gym is quite easy and can be done in one easy step. We are going to do just that in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf70c296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\envs\\registration.py:565: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  f\"The environment {id} is out of date. You should consider \"\n",
      "C:\\ProgramData\\Anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:98: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  \"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"\n"
     ]
    }
   ],
   "source": [
    "## Creating the environment ##\n",
    "\n",
    "cartpole_env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5a33c",
   "metadata": {},
   "source": [
    "Don't get scared by the warning. It's just showing that I am using a lower version of the Cartpole environment. But for this example I really don't care."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d626a8",
   "metadata": {},
   "source": [
    "As always we need to reset the environment to get it to the first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c3d70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01247975, -0.0119193 , -0.01870995,  0.02350845], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reseting the environment ##\n",
    "\n",
    "cartpole_env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784795a8",
   "metadata": {},
   "source": [
    "Now we can check the action space and the observation space of the environment by using simple methods available with the environment. We will be doing this in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66da8b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the action space ##\n",
    "\n",
    "cartpole_env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b865463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the observation space ##\n",
    "\n",
    "cartpole_env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103860e",
   "metadata": {},
   "source": [
    "That's so easy right?\n",
    "\n",
    "So what insights did we gain?\n",
    "\n",
    "- The action space has just 2 values.\n",
    "- The observation space gives out 4 values which are continuous and run through the given range in between the square brackets.\n",
    "\n",
    "Cool.\n",
    "\n",
    "But how do we take an action? What does taking an action return?\n",
    "\n",
    "Well lets see that in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5095c2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01224136,  0.1834659 , -0.01823978, -0.27501845], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Taking a random action ##\n",
    "\n",
    "action = cartpole_env.action_space.sample()\n",
    "\n",
    "cartpole_env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07992d0e",
   "metadata": {},
   "source": [
    "So, we get 4 values by taking a step. The first array is the current observation state. The second value is the reward. The third value depicts if we have reached the terminal state or not and the fourth value queries any additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edc6a0",
   "metadata": {},
   "source": [
    "So with all that, lets now write our basic random cartpole balancing agent using OpenAI Gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27591f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps taken is : 27 and total reward gained is : 27.0\n"
     ]
    }
   ],
   "source": [
    "## Our random cartpole agent ##\n",
    "\n",
    "# Creating the environment #\n",
    "\n",
    "cartpole_env = gym.make('CartPole-v1')\n",
    "\n",
    "# Resetting the environment #\n",
    "\n",
    "obs = cartpole_env.reset()\n",
    "\n",
    "# Initializing a variable to calculate the final reward #\n",
    "\n",
    "total_reward = 0.0\n",
    "\n",
    "# Initialize a variable to calculate the total number of steps taken #\n",
    "\n",
    "total_step = 0\n",
    "\n",
    "# Running till we don't reach a terminal state #\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Grabbing a random action #\n",
    "    \n",
    "    action = cartpole_env.action_space.sample()\n",
    "    \n",
    "    # Agent Taking a step in the environment #\n",
    "    \n",
    "    obs , reward , done , _ = cartpole_env.step(action)\n",
    "    \n",
    "    # Adding reward #\n",
    "    \n",
    "    total_reward += reward\n",
    "    \n",
    "    # Adding step #\n",
    "    \n",
    "    total_step += 1\n",
    "    \n",
    "    # If terminal state is reached breaking the while loop #\n",
    "    \n",
    "    if done:\n",
    "        \n",
    "        break\n",
    "        \n",
    "print('Total steps taken is : {} and total reward gained is : {}'.format(total_step , total_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c69a7",
   "metadata": {},
   "source": [
    "And done. Our random agent took 27 steps before falling down.\n",
    "\n",
    "That's quite impressive :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
